{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Phase 5: Model Deployment\n",
        "\n",
        "This notebook demonstrates comprehensive model deployment techniques for MLOps, covering model packaging, containerization, and serving.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Model Packaging](#1-model-packaging)\n",
        "2. [Model Containerization](#2-model-containerization)\n",
        "3. [Model Serving](#3-model-serving)\n",
        "4. [API Development](#4-api-development)\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "Make sure you have the required libraries installed:\n",
        "```bash\n",
        "pip install pandas numpy scikit-learn fastapi uvicorn docker joblib\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import docker\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries imported successfully!\")\n",
        "\n",
        "# Load the best model from Phase 4\n",
        "try:\n",
        "    # Try to load the best model\n",
        "    model_files = [f for f in os.listdir('models/') if f.startswith('best_model_') and f.endswith('.joblib')]\n",
        "    if model_files:\n",
        "        model_path = f'models/{model_files[0]}'\n",
        "        model = joblib.load(model_path)\n",
        "        print(f\"âœ… Loaded model: {model_path}\")\n",
        "    else:\n",
        "        # Create a dummy model for demo\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        model = RandomForestClassifier(random_state=42)\n",
        "        print(\"âš ï¸  Using dummy model for demo\")\n",
        "except:\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    print(\"âš ï¸  Using dummy model for demo\")\n",
        "\n",
        "print(f\"ðŸ“Š Model type: {type(model).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Packaging\n",
        "\n",
        "**Purpose**: Package model with all dependencies for deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Step 15: Select Best Model\n",
        "print(\"ðŸ† Step 15: Select Best Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Model metadata\n",
        "model_metadata = {\n",
        "    'model_name': type(model).__name__,\n",
        "    'version': '1.0.0',\n",
        "    'created_at': datetime.now().isoformat(),\n",
        "    'model_type': 'classification',\n",
        "    'target_variable': 'default_risk',\n",
        "    'features': ['age', 'income', 'education', 'employment_status', 'credit_score', 'loan_amount'],\n",
        "    'performance_metrics': {\n",
        "        'accuracy': 0.85,  # Example metrics\n",
        "        'precision': 0.82,\n",
        "        'recall': 0.78,\n",
        "        'f1_score': 0.80,\n",
        "        'roc_auc': 0.88\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Selected Model: {model_metadata['model_name']}\")\n",
        "print(f\"Version: {model_metadata['version']}\")\n",
        "print(f\"Performance: {model_metadata['performance_metrics']}\")\n",
        "\n",
        "# 1.2 Step 16: Package Model\n",
        "print(\"\\nðŸ“¦ Step 16: Package Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model_filename = f\"models/{model_metadata['model_name'].lower()}_v{model_metadata['version']}.joblib\"\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"âœ… Model saved: {model_filename}\")\n",
        "\n",
        "# Save metadata\n",
        "metadata_filename = f\"models/{model_metadata['model_name'].lower()}_metadata.json\"\n",
        "with open(metadata_filename, 'w') as f:\n",
        "    json.dump(model_metadata, f, indent=2)\n",
        "print(f\"âœ… Metadata saved: {metadata_filename}\")\n",
        "\n",
        "# Create requirements.txt for model\n",
        "requirements = [\n",
        "    \"pandas>=1.3.0\",\n",
        "    \"numpy>=1.21.0\",\n",
        "    \"scikit-learn>=1.0.0\",\n",
        "    \"joblib>=1.0.0\",\n",
        "    \"fastapi>=0.68.0\",\n",
        "    \"uvicorn>=0.15.0\",\n",
        "    \"pydantic>=1.8.0\"\n",
        "]\n",
        "\n",
        "with open('models/requirements.txt', 'w') as f:\n",
        "    f.write('\\n'.join(requirements))\n",
        "print(\"âœ… Requirements saved: models/requirements.txt\")\n",
        "\n",
        "# 1.3 Step 17: Register Model\n",
        "print(\"\\nðŸ“ Step 17: Register Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Model registry (simplified)\n",
        "model_registry = {\n",
        "    'models': {\n",
        "        model_metadata['model_name']: {\n",
        "            'version': model_metadata['version'],\n",
        "            'path': model_filename,\n",
        "            'metadata_path': metadata_filename,\n",
        "            'status': 'ready_for_deployment',\n",
        "            'registered_at': datetime.now().isoformat()\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save registry\n",
        "registry_filename = 'models/model_registry.json'\n",
        "with open(registry_filename, 'w') as f:\n",
        "    json.dump(model_registry, f, indent=2)\n",
        "print(f\"âœ… Model registered: {registry_filename}\")\n",
        "\n",
        "print(\"âœ… Model packaging completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Containerization\n",
        "\n",
        "**Purpose**: Containerize model for scalable deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Step 18: Containerize Model\n",
        "print(\"ðŸ³ Step 18: Containerize Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create Dockerfile\n",
        "dockerfile_content = f\"\"\"\n",
        "FROM python:3.9-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy requirements and install dependencies\n",
        "COPY models/requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Copy model files\n",
        "COPY models/ ./models/\n",
        "\n",
        "# Copy API code\n",
        "COPY api/ ./api/\n",
        "\n",
        "# Expose port\n",
        "EXPOSE 8000\n",
        "\n",
        "# Run the application\n",
        "CMD [\"uvicorn\", \"api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "\"\"\"\n",
        "\n",
        "with open('Dockerfile', 'w') as f:\n",
        "    f.write(dockerfile_content)\n",
        "print(\"âœ… Dockerfile created\")\n",
        "\n",
        "# Create docker-compose.yml\n",
        "docker_compose_content = \"\"\"\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  ml-api:\n",
        "    build: .\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    environment:\n",
        "      - MODEL_PATH=models/randomforestclassifier_v1.0.0.joblib\n",
        "    volumes:\n",
        "      - ./models:/app/models\n",
        "    restart: unless-stopped\n",
        "\"\"\"\n",
        "\n",
        "with open('docker-compose.yml', 'w') as f:\n",
        "    f.write(docker_compose_content)\n",
        "print(\"âœ… docker-compose.yml created\")\n",
        "\n",
        "# Create .dockerignore\n",
        "dockerignore_content = \"\"\"\n",
        "__pycache__\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        ".Python\n",
        "env\n",
        "pip-log.txt\n",
        "pip-delete-this-directory.txt\n",
        ".tox\n",
        ".coverage\n",
        ".coverage.*\n",
        ".cache\n",
        "nosetests.xml\n",
        "coverage.xml\n",
        "*.cover\n",
        "*.log\n",
        ".git\n",
        ".mypy_cache\n",
        ".pytest_cache\n",
        ".hypothesis\n",
        "\"\"\"\n",
        "\n",
        "with open('.dockerignore', 'w') as f:\n",
        "    f.write(dockerignore_content)\n",
        "print(\"âœ… .dockerignore created\")\n",
        "\n",
        "# 2.2 Docker Build Commands\n",
        "print(\"\\nðŸ”¨ Docker Build Commands\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"To build the Docker image, run:\")\n",
        "print(\"docker build -t ml-model-api .\")\n",
        "print(\"\\nTo run the container, run:\")\n",
        "print(\"docker run -p 8000:8000 ml-model-api\")\n",
        "print(\"\\nOr use docker-compose:\")\n",
        "print(\"docker-compose up --build\")\n",
        "\n",
        "print(\"âœ… Containerization setup completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Serving\n",
        "\n",
        "**Purpose**: Create API endpoints for model serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Step 19: Deploy Model\n",
        "print(\"ðŸš€ Step 19: Deploy Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create API directory\n",
        "os.makedirs('api', exist_ok=True)\n",
        "\n",
        "# 3.2 Step 20: Serve Model via APIs\n",
        "print(\"\\nðŸŒ Step 20: Serve Model via APIs\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create FastAPI application\n",
        "api_code = '''\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"ML Model API\",\n",
        "    description=\"API for Default Risk Prediction\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Load model\n",
        "try:\n",
        "    model = joblib.load(\"models/randomforestclassifier_v1.0.0.joblib\")\n",
        "    logger.info(\"Model loaded successfully\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading model: {e}\")\n",
        "    model = None\n",
        "\n",
        "# Pydantic models for request/response\n",
        "class PredictionRequest(BaseModel):\n",
        "    age: int\n",
        "    income: float\n",
        "    education: str\n",
        "    employment_status: str\n",
        "    credit_score: int\n",
        "    loan_amount: float\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    prediction: int\n",
        "    probability: float\n",
        "    confidence: str\n",
        "    model_version: str\n",
        "\n",
        "# Health check endpoint\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"timestamp\": pd.Timestamp.now().isoformat()\n",
        "    }\n",
        "\n",
        "# Model info endpoint\n",
        "@app.get(\"/model_info\")\n",
        "async def model_info():\n",
        "    if model is None:\n",
        "        raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
        "    \n",
        "    return {\n",
        "        \"model_type\": type(model).__name__,\n",
        "        \"features_count\": model.n_features_in_ if hasattr(model, 'n_features_in_') else \"unknown\",\n",
        "        \"version\": \"1.0.0\"\n",
        "    }\n",
        "\n",
        "# Prediction endpoint\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict(request: PredictionRequest):\n",
        "    try:\n",
        "        if model is None:\n",
        "            raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
        "        \n",
        "        # Prepare features\n",
        "        features = np.array([\n",
        "            request.age,\n",
        "            request.income,\n",
        "            request.credit_score,\n",
        "            request.loan_amount\n",
        "        ]).reshape(1, -1)\n",
        "        \n",
        "        # Make prediction\n",
        "        prediction = model.predict(features)[0]\n",
        "        probability = model.predict_proba(features)[0].max()\n",
        "        \n",
        "        # Determine confidence level\n",
        "        if probability > 0.8:\n",
        "            confidence = \"high\"\n",
        "        elif probability > 0.6:\n",
        "            confidence = \"medium\"\n",
        "        else:\n",
        "            confidence = \"low\"\n",
        "        \n",
        "        return PredictionResponse(\n",
        "            prediction=int(prediction),\n",
        "            probability=float(probability),\n",
        "            confidence=confidence,\n",
        "            model_version=\"1.0.0\"\n",
        "        )\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Prediction error: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Internal server error\")\n",
        "\n",
        "# Batch prediction endpoint\n",
        "@app.post(\"/predict_batch\")\n",
        "async def predict_batch(requests: List[PredictionRequest]):\n",
        "    try:\n",
        "        if model is None:\n",
        "            raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
        "        \n",
        "        # Prepare batch features\n",
        "        features_list = []\n",
        "        for req in requests:\n",
        "            features = [\n",
        "                req.age,\n",
        "                req.income,\n",
        "                req.credit_score,\n",
        "                req.loan_amount\n",
        "            ]\n",
        "            features_list.append(features)\n",
        "        \n",
        "        features_array = np.array(features_list)\n",
        "        \n",
        "        # Make predictions\n",
        "        predictions = model.predict(features_array)\n",
        "        probabilities = model.predict_proba(features_array).max(axis=1)\n",
        "        \n",
        "        # Prepare responses\n",
        "        responses = []\n",
        "        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
        "            confidence = \"high\" if prob > 0.8 else \"medium\" if prob > 0.6 else \"low\"\n",
        "            responses.append({\n",
        "                \"prediction\": int(pred),\n",
        "                \"probability\": float(prob),\n",
        "                \"confidence\": confidence,\n",
        "                \"model_version\": \"1.0.0\"\n",
        "            })\n",
        "        \n",
        "        return {\"predictions\": responses}\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Batch prediction error: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Internal server error\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "'''\n",
        "\n",
        "# Save API code\n",
        "with open('api/main.py', 'w') as f:\n",
        "    f.write(api_code)\n",
        "print(\"âœ… API code created: api/main.py\")\n",
        "\n",
        "# 3.3 Step 21: Inference (Real-time Predictions)\n",
        "print(\"\\nâš¡ Step 21: Inference (Real-time Predictions)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test the API locally\n",
        "print(\"To test the API locally, run:\")\n",
        "print(\"uvicorn api.main:app --reload\")\n",
        "print(\"\\nThen visit: http://localhost:8000/docs\")\n",
        "print(\"\\nExample API calls:\")\n",
        "print(\"\"\"\n",
        "# Health check\n",
        "curl http://localhost:8000/health\n",
        "\n",
        "# Single prediction\n",
        "curl -X POST \"http://localhost:8000/predict\" \\\\\n",
        "     -H \"Content-Type: application/json\" \\\\\n",
        "     -d '{\n",
        "       \"age\": 35,\n",
        "       \"income\": 75000,\n",
        "       \"education\": \"Bachelor\",\n",
        "       \"employment_status\": \"Employed\",\n",
        "       \"credit_score\": 720,\n",
        "       \"loan_amount\": 50000\n",
        "     }'\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Model serving setup completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
